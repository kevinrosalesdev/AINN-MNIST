{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_neuralnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinrosalesdev/AINN-MNIST/blob/master/mnist_neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVbTJd0e4GI",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Neural Network\n",
        "## Neural Network to identify a number from a picture.\n",
        "\n",
        "We are going to build a *Neural Network* that classifies numbers from [**MNIST Dataset**](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "**MNIST Dataset contains a large amount of 28x28 pictures about handwritten numbers from 0 to 9.**\n",
        "\n",
        "We will take a huge dataset part to *train* our Neural Network and after that, other part will be taken to *test* our project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diq0Xif3CUhN",
        "colab_type": "text"
      },
      "source": [
        "## First, we load data and introduce some parameters for our Model:\n",
        "It's necessary to reshape and normalize data in order to introduce pixels values in our Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI-iN2cSe4GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import keras\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)  # 28x28=784\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255  # We normalize to have values between 0 and 1\n",
        "X_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)  # onehot encoding\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTWLqqmLe4GO",
        "colab_type": "text"
      },
      "source": [
        "## We build the Neural Network Model:\n",
        "\n",
        "*   We create a Model with an input layer that contains 784 inputs (28x28 pixels).\n",
        "*   Then, we add three hidden layers (with 980, 500 and 17 neurons). We use [*Relu*](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) as activation function.\n",
        "*   Finally, we use an output layer with 10 neurons as we have 10 different numbers (Remember that we are classifying from 0 to 9!). We use [*SoftMax*](https://en.wikipedia.org/wiki/Softmax_function) as activation function as we need to classify more than 1 Output.\n",
        "\n",
        "We use *RMSProp* as **Optimizer** and *Categorical Crossentropy* as **Loss Function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjdV7YZ8e4GQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c20f9dcf-f0d4-4a74-a112-36776e0ceba3"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD #Stochastic Gradient Descent Optimizer\n",
        "\n",
        "inputs = Input(shape=(784,))  # We have 784 inputs\n",
        "x = Dense(1000, activation='relu')(inputs)  # 1000 neurons and relu as activation function\n",
        "y = Dense(500, activation='relu')(x) # 500 neurons and relu as activation function\n",
        "z = Dense(25, activation='relu')(y)  # 25 neurons and relu as activation function\n",
        "predictions = Dense(num_classes, activation='softmax')(z)  # Output layer with 10 neurons, one for each class\n",
        "\n",
        "# This creates a model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Instead of using MSE as Loss & SGD as Optimizer, I used Categorical Crossentropy & RMSProp to get adaptive LR and better results.\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',  # Categorical Crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 25)                12525     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 1,298,285\n",
            "Trainable params: 1,298,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24BRiNxbe4GZ",
        "colab_type": "text"
      },
      "source": [
        "## We train our Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U30cMfHIe4Gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a9c47316-425e-41a3-df97-012733b3eae1"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)  # starts training with 5 epochs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2538 - acc: 0.9211\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0873 - acc: 0.9741\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0593 - acc: 0.9823\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0437 - acc: 0.9869\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0347 - acc: 0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8b032d5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ekBnr1e4Gh",
        "colab_type": "text"
      },
      "source": [
        "## Some Tests:\n",
        "We can see some **Output Values** from our **Model**. We can try to get how many outputs have been classified **correctly**.\n",
        "\n",
        "*Test* samples are separated from *Training* samples so we can try to study the existence of **Overfitting**.\n",
        "\n",
        "Feel free to uncomment print line if you want to see **Full Output**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TH9HutaQe4Gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3a4b195-fc70-41d7-ebba-aeddc11d18d5"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "import numpy\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "for p, l in zip(predictions, y_test):\n",
        "    if l[numpy.where(p == p.max())] == 1:\n",
        "      correct += 1\n",
        "    else:\n",
        "      incorrect += 1\n",
        "    #print(p,\"->\", l)\n",
        "print(\"Correct: \", correct)\n",
        "print(\"Incorrect: \", incorrect)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct:  9817\n",
            "Incorrect:  183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fZwqnsuIwPn",
        "colab_type": "text"
      },
      "source": [
        "## Stats\n",
        "\n",
        "Approximately, 9817 out of 10000 samples have been classified correctly. In consequence, **Overfitting is not a problem in this Model.**\n",
        "\n",
        "Approximate Stats:\n",
        "\n",
        "1.   Model Accuracy: 99%\n",
        "2.   Model Loss: 3%\n",
        "3.   Real Model Accuracy: 98%\n"
      ]
    }
  ]
}